{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Lista de Exercícios 04\n",
    "\n",
    "Vamos continuar a implementação de nossas bibliotecas de machine learning na forma mais simples possível usando no Python e o NumPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Crie os seguintes arquivos com extensão .py e implemente os métodos definidos para cada um deles:**\n",
    "  * transform.py\n",
    "    * standardize\n",
    "    * normalize\n",
    "  * resample.py\n",
    "    * **split_k_fold(n_elem, n_splits=3, shuffle=True, seed=0)**\n",
    "    * n_elem - número total de elementos.\n",
    "    * n_split - número de folds. Mínimo: 2.\n",
    "    * shuffle - aleatoriza a ordem dos dados (True) ou não (False).\n",
    "    * seed - determina uma semente para geração de números aleatórios ou não (None).\n",
    "    * Retorno: 2 arrays (**idx_train e idx_test**), cada um com **n_splits** elementos: \n",
    "      * um com os índices de treino. Exemplo para **n_splits=3**, teremos idx_train[0], idx_train[1] e idx_train[2].\n",
    "      * um com os índices de teste. Exemplo para **n_splits=3**, teremos idx_test[0], idx_test[1] e idx_test[2].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Use sua implementação de split_k_fold a fim de fazer Cross Validation com k=5 (5-Fold) para obter o MSE de regressões para o seguinte dataset sobre a qualidade de vinhos tintos (winequality-red.csv) (para obter detalhes sobre o dataset clique aqui). Compare as seguintes técnicas de regressão (pode usar as implementações do Scikit Learn):**\n",
    "  * [SGD - Stochastic Gradient Descent Regressor]()\n",
    "  * [Linear Regression ]()\n",
    "  * [Linear SVR]()\n",
    "  * [SVR - Epsilon-Support Vector Regression]()\n",
    "  * [Random Forest Regressor]()\n",
    "  * [Gradient Boosting Regressor]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Faça um gráfico comparativo entre resultados das avaliações (Evaluation) dos modelos acima.**\n",
    "  * Dica: o Notebook do seguinte link pode servir de inspiração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Escolha o melhor algoritmo obtido a partir de cross validation e treine um modelo usando o dataset completo, ou seja, gere um modelo final.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Qual a diferença entre Stochastic Gradient Descent e Gradient Descent? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
